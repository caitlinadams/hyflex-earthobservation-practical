{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db48afad-0d8c-4914-970e-66f7baeb5866",
   "metadata": {},
   "source": [
    "# Analysing forest recovery after logging events - comparison with satellite data\n",
    "\n",
    "During the previous practical, you learned about the data that the Victorian Department of Environment, Land, Water and Planning keep on the harvesting of logging events over time, and exported all the events that can be easily compared with satellite data from the Sentinel-2 constellation.\n",
    "\n",
    "Your team has reviewed your file and selected three known logging events, which they would like you to investigate. Each event has a different type of harvesting strategy, and your team are curious about how these events show up in satellite data. \n",
    "\n",
    "In this practical, you'll load and view the satellite data associated with each logging event, both as an image, and using the normalised difference vegetation index (NDVI). You'll then view the time series of how NDVI is changing over time for each event. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115a72b-9a72-4c5a-8196-dd9231c9681f",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "During this activity, you will learn to\n",
    "\n",
    "* select specific rows from a table of geospatial data\n",
    "* load satellite data for the time and location corresponding to a given logging event\n",
    "* review satellite data, both as images and as timeseries\n",
    "\n",
    "All of the Python code for this session has been provided for you. The focus of this session is to review the results and think about what you can learn from satellite data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b1ee6-a12c-40eb-8232-60daacfa64e1",
   "metadata": {},
   "source": [
    "## Notebook setup\n",
    "\n",
    "In addition to `pandas` and `geopandas`, you'll now also need the `datacube` package; this is what lets you load satellite data. The other analyst on your team has also provided a number of extra functions that you'll use throughout the notebook.\n",
    "\n",
    "To run the code, click on the next cell, and press `Shift`+`Enter` on your keyboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b2aec-9f91-4031-8068-8352eafc59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import key packages\n",
    "import datacube\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import extra functions\n",
    "from datacube.utils.geometry import Geometry\n",
    "from dea_tools.datahandling import load_ard\n",
    "from dea_tools.spatial import xr_rasterize\n",
    "from odc.algo import xr_geomedian\n",
    "from plotting_functions import plot_rgb_ndvi\n",
    "\n",
    "# Change a pandas setting to view all columns and all rows of loaded data\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad85bb3-a483-4912-9af0-2e650889481f",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "In the last practical, you exported a file called \"LOG_SEASON_FILTERED.gpkg\" to the \"data\" folder in your workspace. This contains all the logging events that can be matched with Sentinel-2 data. \n",
    "\n",
    "The code in the next cell will load the \"LOG_SEASON_FILTERED.gpkg\" file, and assign it to a variable called `logging_season_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902adc8-da96-4cc7-afb8-0534d92a9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_season_data = gpd.read_file(\"data/LOG_SEASON_FILTERED.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9d83be-f48b-476f-9deb-fbf4b033a830",
   "metadata": {},
   "source": [
    "It is a good idea to look at the first five rows of your loaded data to check it has been imported correctly. To do this, you can use the `.head()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d338369-60b4-471e-8b4d-1127672283cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_season_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e1e79-b812-465e-8796-bcb4899e469b",
   "metadata": {},
   "source": [
    "## Select logging events for analysis\n",
    "\n",
    "Your team has identified three logging events for you to investigate, with each event demonstrating a different harvesting approach. They have provided you with the event LOGHISTID values so that you can select them from your list of events:\n",
    "\n",
    "**Clearfelling event**: \"14/770/507/0011/201920/00\"\n",
    "**Regrowth retention harvesting event**: \"08/286/505/0029/201920/00\"\n",
    "**Variable retention 1 event**: \"16/686/510/0026/201920/00\"\n",
    "\n",
    "Your colleague has provided these event keys as a Python dictionary, and has provided some code to only select the rows in your dataset with these LOGHISTID values. Run the cells below, and then complete the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55e546-1426-4185-a8df-b2fa2ff627d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_of_interest = {\n",
    "    \"Clearfelling\": \"14/770/507/0011/201920/00\",\n",
    "    \"Regrowth retention harvesting\": \"08/286/505/0029/201920/00\",\n",
    "    \"Variable retention 1\": \"16/686/510/0026/201920/00\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749104b-b9f0-4316-8dbc-3602d1429aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list containing the IDs from the dictionary\n",
    "event_ids = list(events_of_interest.values())\n",
    "\n",
    "# Identify the rows that correspond to the IDs in the list\n",
    "rows_of_interest = logging_season_data.loc[:, \"LOGHISTID\"].isin(event_ids)\n",
    "\n",
    "# Make a new table only containing the rows of interest\n",
    "logging_events_to_analyse = logging_season_data.loc[rows_of_interest, :].reset_index(drop=True)\n",
    "\n",
    "# View the new table\n",
    "logging_events_to_analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba1e45-0d1b-47ad-914e-b6ac585086ea",
   "metadata": {},
   "source": [
    "### Exercise: Reviewing the events\n",
    "\n",
    "Your team is interested in the answers to the following questions:\n",
    "\n",
    "* **Question 1**: What is the earliest start date across the three events?\n",
    "* **Question 2**: What is the latest end date across the three events?\n",
    "* **Question 3**: Which tree species was harvested in all three events?\n",
    "\n",
    "> **Your task**: Review the table of selected events above, and answer the questions below.\n",
    "\n",
    "> Double click the text below to add your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11095656-0517-48c2-ad16-95828dceded8",
   "metadata": {},
   "source": [
    "### Your answers\n",
    "\n",
    "**Question 1**: \n",
    "\n",
    "**Question 2**:\n",
    "\n",
    "**Question 3**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9ed663-339d-4ced-98fa-db9910c3c8fd",
   "metadata": {},
   "source": [
    "## Loading satellite data for each event\n",
    "\n",
    "### Connecting to the datacube and constructing the query\n",
    "\n",
    "In the next cell, your colleauge has provided you with the code to connect to the datacube, and some recommended settings for loading the data. The recommended settings are as follows:\n",
    "\n",
    "* **time_range**: The date range to search for data over. Your colleague suggests looking at events sometime before and after the actual events.\n",
    "* **products**: the satellite data to load from. \"s2a_ard_granule\" is the analysis-ready data product for Sentinel-2A, and \"s2b_ard_granule\" is the analysis-ready data product for Sentinel-2B.\n",
    "* **measurements**: the Sentinel-2 bands to load. The \"nbart_\" prefix has to do with how the data have been processed. For visual interpretation, you need the red, green and blue bands. For calculating NDVI, you need the red and near-infrared (nir_1) bands.\n",
    "* **resolution**: the resolution (in metres) for each pixel in the image. The first number (-10) specifies 10m in the vertical direction, and the second number (10) specifies 10m in the horizontal direction.\n",
    "* **output_crs**: the coordinate reference system (CRS) to use for the loaded data. [EPSG:3577](https://epsg.io/3577) is the Australian Albers equal-area projection.\n",
    "* **min_gooddata**: The proportion of pixels in the image that must be good quality (i.e. not cloudy) for the whole image to be loaded. This makes sure we only load data with minimal cloud coverage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e11cc-3bcd-4bf0-8ce7-2c812153156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the datacube\n",
    "dc = datacube.Datacube(app=\"Logging_analysis\")\n",
    "\n",
    "# Recommended settings\n",
    "time_range = (\"2019-06-01\", \"2020-12-31\")\n",
    "products = [\"s2a_ard_granule\", \"s2b_ard_granule\"]\n",
    "measurements = [\"nbart_red\", \"nbart_green\", \"nbart_blue\", \"nbart_nir_1\"]\n",
    "resolution = (10, -10)\n",
    "output_crs = \"EPSG:3577\"\n",
    "min_gooddata = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aed65c-1a4d-426a-bf39-8939592e2307",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    "The next cell contains multiple steps that are used to load the data for each event. This is done by using a Python `for` loop, which loads data for each event in turn, and stores the outputs.\n",
    "\n",
    "> **The data loading step will take 5 minutes!** \n",
    "\n",
    "Please be patient and watch the output. You can read more about the steps involved as the code runs. The steps are described below the next cell. You will know it is finished when you see the message \"All data loading is complete! You can progress to the next step.\".\n",
    "\n",
    "> **When running the code, the following warning may appear**: `CPLReleaseMutex: Error = 1 (Operation not permitted)`. This is normal and you don't need to worry.\n",
    "\n",
    "Run the code cell below, then scroll down to read about the steps while the data loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84267494-1128-406d-9c00-9a70119e2056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the settings into a dictionary, which can be used for all three events.\n",
    "query = {\n",
    "    \"time\": time_range,\n",
    "    \"products\": products,\n",
    "    \"measurements\": measurements,\n",
    "    \"resolution\": resolution,\n",
    "    \"output_crs\": output_crs,\n",
    "    \"min_gooddata\": min_gooddata,\n",
    "    \"group_by\": \"solar_day\",\n",
    "}\n",
    "\n",
    "# Create empty dictionary to store results in\n",
    "event_data = {}\n",
    "\n",
    "for (event_type, event_id) in events_of_interest.items():\n",
    "\n",
    "    print(f\"Analysing LOGHISTID {event_id}; Event type: {event_type}\")\n",
    "\n",
    "    # Select the row corresponding to the LOGHISTID value\n",
    "    event = logging_events_to_analyse.loc[logging_events_to_analyse.LOGHISTID == event_id]\n",
    "\n",
    "    # Get the polygon geometry for the event and add it to the query\n",
    "    geometry = Geometry(geom=event.geometry.values[0], crs=logging_events_to_analyse.crs)\n",
    "    query.update({\"geopolygon\": geometry})\n",
    "\n",
    "    # Load the data useing the query\n",
    "    ds = load_ard(dc=dc, **query)\n",
    "\n",
    "    # Generate a polygon mask to keep only data within the polygon and apply the mask\n",
    "    mask = xr_rasterize(event, ds)\n",
    "    ds = ds.where(mask)\n",
    "\n",
    "    # Group by 3 month intervals and calculate a composite dataset using the geomedian\n",
    "    grouped = ds.resample(time=\"3MS\")\n",
    "    composite = grouped.map(xr_geomedian)\n",
    "\n",
    "    # Calculate NDVI using (NIR - Red)/(NIR + Red)\n",
    "    composite[\"NDVI\"] = (composite.nbart_nir_1 - composite.nbart_red) / (composite.nbart_nir_1 + composite.nbart_red)\n",
    "\n",
    "    # Store the results in the event_data dictionary\n",
    "    event_data[event_type] = composite\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "print(\"All data loading is complete! You can progress to the next step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a5943-6982-499e-bdd1-9a6e8fd8f917",
   "metadata": {},
   "source": [
    "### Description of steps for loading data\n",
    "\n",
    "The Python for loop allows us to repeat the same set of actions for each event. The actions are:\n",
    "\n",
    "1. **Select the row corresponding to the LOGHISTID value.**\n",
    "\n",
    "2. **Get the polygon geometry for the event and add it to the query.** This means the datacube will only return data relevent to the event area.\n",
    "\n",
    "3. **Load the data useing the query.** The `load_ard()` function takes the datacube connection and the query, and loads the relevent data.\n",
    "\n",
    "4. **Generate a polygon mask to keep only data within the polygon and apply the mask.** This maps the geometry to a raster with ones and zeros, where ones correspond to pixels within the area of interest, and zeros correspond to areas outside the area of interest. This will allow us to isolate out pixels corresponding to the logging event.\n",
    "\n",
    "5. **Group by 3 month intervals and calculate a composite dataset using the geomedian.** This step allows us to create a representative dataset over a three month period, by selecting the median pixel value from all values loaded for that period. In this case, we use a special type of median, called the geomedian. You can read more about it in the [Digital Earth Africa documentation](https://docs.digitalearthafrica.org/en/latest/data_specs/GeoMAD_specs.html#Geomedian) if you are curious (it is not required to complete the practical).\n",
    "\n",
    "6. **Calculate NDVI using (NIR - Red)/(NIR + Red)**. This step takes the loaded red and near-infrared bands from the composite and calculates the corresponding NDVI values. NDVI is a satellite band index that indicates the presence of vegetation, with values ranging from -1 to 1. Higher values typically correspond to dense, green vegetation.\n",
    "\n",
    "7. **Store the results in the event_data dictionary**. This step allows us to store the data for each event and use it for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2244e1-1588-4dc9-9f2f-3217455c2ed5",
   "metadata": {},
   "source": [
    "## Visualising loaded data\n",
    "\n",
    "### Spatial time series\n",
    "Plotting data in Python can be a little tricky, so your colleague has dug out an old function they once made to help you. The function is called `plot_rgb_ndvi()` and it takes event data and the name of the event type to use as a title. It will show the visual image of the logging area (the combination of red, green and blue bands) on the left-hand side, and the corresponding NDVI values on the right hand side. It will plot each composite that was generated, one after the other.\n",
    "\n",
    "Run the following cell to view the RGB and NDVI images for each logging event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc8c9e-23b7-4ea6-a04f-669258262e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RGB and NDVI for the event areas\n",
    "for event_type, event_ds in event_data.items():\n",
    "    plot_rgb_ndvi(event_ds, event_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774985d4-ebb1-44ed-82c3-81b5710453f1",
   "metadata": {},
   "source": [
    "### Summary time series\n",
    "\n",
    "Your colleague has provided additional code to calculate and plot the average NDVI value for each composite, which will allow you to see the general trend in the presence of vegetation for the three events.\n",
    "\n",
    "Run the cell below to view the average NDVI over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5161f7-39b5-439e-9b6a-d6fe10f8edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the plot labels to add at the end\n",
    "labels = []\n",
    "\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Add a title\n",
    "fig.suptitle(\"Change in NDVI over time for different logging events\", fontsize=16)\n",
    "\n",
    "# Plot the mean (average) NDVI for each event\n",
    "for event_type, event_ds in event_data.items():\n",
    "    event_ds.NDVI.mean(dim=[\"x\", \"y\"]).plot(add_legend=False, ax=ax)\n",
    "    labels.append(event_type)\n",
    "\n",
    "# Add the labels and display the plot\n",
    "plt.legend(labels, ncol=1, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d537592-e9e2-48bb-8251-bccc46dfa572",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Congratulations! You have successfully loaded and visualised satellite data for the three logging events! Now, your colleagues are curious to know what you found.\n",
    "\n",
    "Your team ask you to report back on the following:\n",
    "\n",
    "* **Analysis Question 1**: In 1-2 sentences, please describe one similarity you noticed between the three events when looking at the RGB and NDVI spatial time series.\n",
    "* **Analysis Question 2**: In 1-2 sentences, please describe one difference you noticed between the three events when looking at the RGB and NDVI spatial time series.\n",
    "* **Analysis Question 3**: When looking at the summary time series for the Clearfelling event, around what month and year would you say the Clearfelling began? Is this consistent with the start date in the event table you created when [selecting logging events for analysis](#Select-logging-events-for-analysis)?\n",
    "\n",
    "> **Your task**: Review the spatial and summary time series, and answer the analysis questions below.\n",
    "\n",
    "> Double click the text below to add your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77538e0-86e1-47c0-886f-a52ef7af7cce",
   "metadata": {},
   "source": [
    "### Your answers\n",
    "\n",
    "**Analysis Question 1**: \n",
    "\n",
    "**Analysis Question 2**:\n",
    "\n",
    "**Analysis Question 3**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a13ed1-9e52-4c09-b9f6-44ebdd7c27df",
   "metadata": {},
   "source": [
    "## Submit your work\n",
    "\n",
    "1. Ensure you have added answers to all the questions and save your file (in the menu bar, click File > Save Notebook).\n",
    "\n",
    "2. In the file browser, right-click the `prac2_logging_site_monitoring.ipynb` file, and press \"Download\"\n",
    "\n",
    "3. Email the downloaded file to caitlinisabeladams@swin.edu.au"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
